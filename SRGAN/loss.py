from torchvision.models import vgg19, VGG19_Weights
import torch
import torch.nn as nn


class VGGLoss(nn.Module):
    """Calculate the VGG loss between generated and ground truth images.

    This loss measures the difference in feature representations extracted from
    the VGG19 model, specifically the features up to the last convolution before
    the MaxPooling layer (the fifth one).

    Args:
        device (str): The device (cpu or cuda) on which to run the VGG model.
        max_feature (int, optional): the VGG19 feature map from where to take the
        metric. Defaults to 36 (happens to be the last convolution before the
        MaxPooling layer).
    """

    def __init__(self, device: str, max_feature=36):
        super().__init__()
        # This will get by default up to the last Convolution before
        # the MaxPooling layer, the fifth one, that happens to be the
        # one used to compute the vgg loss for the best performing
        # model in the paper
        self.vgg = (
            vgg19(weights=VGG19_Weights.DEFAULT)
            .features[:max_feature]
            .eval()
            .to(device)
        )
        for param in self.vgg.parameters():
            param.requires_grad = False
        self.mse = nn.MSELoss()

    def forward(self, gen, gt) -> torch.Tensor:
        """Generate the content loss as the MSE between
        the feature map generated by G(x) -image generated by
        the generator- and the ground truth.

        Args:
            gen (_type_): image generated by the generator
            gt (_type_): ground truth

        Returns:
            torch.Tensor: scalar tensor
        """
        gen_vgg = self.vgg(gen)
        gt_vgg = self.vgg(gt)
        return self.mse(gen_vgg, gt_vgg)
